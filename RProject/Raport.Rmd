---
title: "Analiza danych krystalograficznych w R pochodzących z bazy Protein Data Bank (PDB)"
author: "Michał Hejduk"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    theme: united
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Wstęp

Analiza zbioru była dosyć skomplikowana z powodu dużej liczby kolumn.

Dodatkowo nie ułatwiała tego dość egzotyczna, biologiczna dziedzina.

Problemy pojawiły się przy określaniu korelacji pomiędzy kolumnami, gdzie część nie była numeryczna, a poza tym, nie sposób było pokazać wszystkich równocześnie.


#1. Wykorzystane biblioteki
```{r bilbioteki, warning=FALSE, message=FALSE, hide = TRUE}
library(dplyr)
library(tibble)
library(tidyr) #transformowanie danych
library(ggplot2)
library(plotly)
library(kableExtra) #ładne tabele
library(data.table) #%like%
library(corrplot)
library(caret)
```

#2. Powtarzalność wyników przy każdym uruchomieniu raportu na tych samych danych

``` {r powtarzalnosc}

set.seed(23)
```

#3. Wczytanie danych z pliku

Wczytujemy dane z pliku all_summary.csv. 
Za pomocą heurystyki wyznaczamy klasy pierwszych 100 wierszy.

```{r dane, results='hide', cache=TRUE}

filePath = "C:/Users/micha/Downloads/all_summary.csv"
initial <- read.table(filePath, nrows = 100, sep = ";", header = TRUE)
classes <- sapply(initial, class)
file_data <- read.table(filePath, colClasses = classes, sep = ";", na.strings = 'nan', nrows = 10000, header = TRUE)
data <- file_data
```

Dane znajdują się w zmiennej data.



#4. Wstępne czyszczenie danych

Liczba wierszy w zbiorze: `r nrow(data)`.

Usuwamy wiersze posiadające wartość zmiennej ref_name równą: “UNK”, “UNX”, “UNL”, “DUM”, “N”, “BLOB”, “ALA”, “ARG”, “ASN”, “ASP”, “CYS”, “GLN”, “GLU”, “GLY”, “HIS”, “ILE”, “LEU”, “LYS”, “MET”, “MSE”, “PHE”, “PRO”, “SEC”, “SER”, “THR”, “TRP”, “TYR”, “VAL”, “DA”, “DG”, “DT”, “DC”, “DU”, “A”, “G”, “T”, “C”, “U”, “HOH”, “H20”, “WAT”

```{r wiersze}
res_names_to_remove <- c('UNK', 'UNX', 'UNL', 'DUM', 'N', 'BLOB', 'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'MSE', 'PHE', 'PRO', 'SEC', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'DA', 'DG', 'DT', 'DC', 'DU', 'A', 'G', 'T', 'C', 'U', 'HOH', 'H20', 'WAT')
data <- filter(data, !res_name %in% res_names_to_remove)
```

Liczba wierszy w zbiorze po usunięciu wierszy z ww. wartościami res_name: `r nrow(data)`.



#5. Analiza brakujących danych

W poniższej sekcji oczyścimy dane z kolumn i wierszy zawierających wartości NaN.

Na początku analiza kolumn. 

Wyznaczamy kolumny, które zawierają przynajmniej jedną wartość NaN, grupujemy po nazwie.

```{r brakujace_dane, cache=TRUE, warning=FALSE, message=FALSE }

column_value_DT <- gather(data, "column_name", "val", 1:ncol(data))
columns_with_nans <- filter(column_value_DT, is.na(column_value_DT$val))[,1]

```

Wyświetlamy podsumowanie:

```{r brakujace_dane2}

table(columns_with_nans)
```

Jak widać na podsumowaniu powyżej, dla wszystkich wierszy kolumna weight_col ma wartość NaN.
Usuwamy ją ze zbioru danych:

``` {r usun_weight_col}
data <- data[,-which(names(data) == 'weight_col' )]
```

Widać również, że część wierszy nie posiada wartości dla kolumn zaczynających się od part_02 oraz part_01. 

W celu oczyszczenia danych usuwamy te wiersze.

``` {r usuniecie_wierszy_z_nan}

    all_rows_count <- nrow(data)
    data <- data[complete.cases(data),]
    cleaned_rows_count <- nrow(data)
    removed_rows_count <- all_rows_count - cleaned_rows_count 
```

Usunięto `r removed_rows_count` wierszy. Stanowi to `r removed_rows_count*100/all_rows_count ` % wszystkich wierszy.



#6. Podsumowanie danych

Liczba wierszy: `r nrow(data)` 

Liczba kolumn: `r ncol(data)`

Liczba unikalnych wartości res_name: `r length(unique(data$res_name))`

Poniżej rozmiar data frame w pamięci (w Mb):

``` {r size}
print(object.size(data), units='Mb')
```



#7. Ograniczenie liczby klas do 50 najpopularniejszych wartości

W tej sekcji filtrujemy dane do wierszy, których klasa znajduje się wśród 50 najpopularniejszych.

Na początku grupujemy dane po atrybucie res_name i sortujemy.


```{r ograniczenie1}
top50 <- sort(table(data$res_name), decreasing=TRUE)[1:50]
top50names <- names(top50)


```

Poniżej znajduje się posortowana lista 50 najpopularniejszych klas.

```{r ograniczenie2}
top50names
```


Filtrujemy za pomocą wyznaczonych 50 nazw

```{r ograniczenie3}
data <- filter(data, res_name %in% top50names)
data$res_name <- droplevels(data$res_name)
```


Pozostało `r nrow(data)` wierszy.


#8. Korelacja między zmiennymi

Korelację wyznaczamy dla kolumn numerycznych.

Pomijamy kolumny: "blob_coverage" "res_coverage"  "title"         "pdb_code"      "res_name"
 "chain_id"      "skeleton_data" "fo_col"        "fc_col"  
 
Dla zbioru danych korelację wyznaczamy za pomocą funkcji cor.

Następnie prezentujemy wyniki, za pomocą funkcji corrplot.
 
```{r korelacje, cache=TRUE, warning = FALSE, message=FALSE }

is_numeric_column_list <- unlist(lapply(data, is.numeric))

numeric_data <- data[, is_numeric_column_list]

cor_data <- cor(numeric_data, use = "pairwise.complete.obs") 

#pdf(file = "korelacja_miedzy_kolumnami_FULL.pdf")
corrplot(cor_data, method = "color", tl.col="black",
         tl.cex = 0.2, cl.cex = 0.2, title = "Korelacja między kolumnami")
#dev.off()

```

Z racji dużego rozmiaru macierzy (402 x 402) wykres jest nieczytelny. 

Wynik można zobaczyć również w wyeksportowanym pliku pdf: korelacja_miedzy_kolumnami.pdf

W celu zwiększenia widoczności, ogarniczymy liczbę kolumn, tylko do tych zaczynających się od part_01:

```{r korelacje2, cache=TRUE, warning = FALSE, message=FALSE }

is_part_01_column <- colnames(numeric_data) %like% 'part_01'
part_01_column_names <- colnames(numeric_data)[is_part_01_column]
filtered_numeric_data <- numeric_data[is_part_01_column]

cor_data2 <- cor(filtered_numeric_data, use = "pairwise.complete.obs") 

#pdf(file = "korelacja_miedzy_kolumnami_part_01.pdf")
corrplot(cor_data2, tl.col="black", order = "FPC",
         tl.cex = 0.3, title = "Korelacja między kolumnami")
#dev.off()

```

W pliku "korelacja_miedzy_kolumnami_part_01.pdf" znajduje się powyższa wizualizacja.

Dodatkowo sprawdzamy korelację dla kolumn nie zaczynających się od part (których jest najwięcej), oraz skeleton.

```{r korelacje3, cache=TRUE, warning = FALSE, message=FALSE }

no_part_skeleton_data <- numeric_data %>% select(-starts_with("part")) %>% select(-starts_with("skeleton"))

cor_data3 <- cor(no_part_skeleton_data, use = "pairwise.complete.obs") 
cor_data3[is.na(cor_data3)] <- 0

#pdf(file = "korelacja_miedzy_kolumnami_no_part_skeleton.pdf")
corrplot(cor_data3, tl.col="black", order = "FPC", method = "square",
         tl.cex = 0.5, title = "Korelacja między kolumnami")
#dev.off()

```

Tutaj z racji dużo mniejszej liczby kolumn, wykres jest bardziej czytelny.

Jak można zauważyć, większość kolumn zawierających w swojej nazwie słowo atom, jest silnie skorelowana.

#9. Liczba przykładów dla każdej klasy
```{r ile_przykladow}
sort(table(data$res_name), decreasing=TRUE)

```

#10. Wykresy rozkładów liczby atomów (local_res_atom_non_h_count) i elektronów (local_res_atom_non_h_electron_sum)

```{r wykres1}

chart_data_1 <- ggplot(data, aes(x = data$local_res_atom_non_h_count))
chart_layout_1 <- geom_histogram(col = 'blue', fill = 'orange', binwidth = 1)
chart1 <- chart_data_1 + chart_layout_1 + labs(title="Rozkład liczby atomów") + labs(x="Liczba atomów")
chart1

```

```{r wykres2}

chart_data_2 <- ggplot(data, aes(x = data$local_res_atom_non_h_electron_sum))
#chart_layout_2 <- geom_histogram(col = 'blue', fill = 'orange', binwidth = 5)
chart2 <- chart_data_2 + chart_layout_1 + labs(title="Rozkład liczby elektonów") + labs(x="Liczba elektronów")
chart2
```


#11. Analiza klas pod względem niezgodności liczby atomów i elektronów

Na początek wybieramy interesujące nas kolumny do porównań: local_res_atom_non_h_count, oraz dict_atom_non_h_count. Dodatkowo każdy wiersz zawiera nazwę klasy.  

```{r niezgodnosc}

atoms_incompatibility <- unique(select(data, res_name, local_res_atom_non_h_count, dict_atom_non_h_count))

```

Dodajemy kolumnę z różnicą, wyliczoną na postawie 2 innych.

```{r niezgodnosc2}

atoms_incompatibility_with_diff <- mutate(atoms_incompatibility, diff = abs(local_res_atom_non_h_count - dict_atom_non_h_count))

```

Sortujemy i wyświetlamy 5 pierwszych.

```{r niezgodnosc3}

atoms_incompatibility_with_diff_sorted <- atoms_incompatibility_with_diff[order(-atoms_incompatibility_with_diff$diff),]
head(atoms_incompatibility_with_diff_sorted, 5)

```

Poniżej znajduje się tabela pokazująca 10 klas z największą niezgodnością liczby atomów:

```{r niezgodnosc4}

atoms_table_data <- select(atoms_incompatibility_with_diff_sorted, res_name, diff)[1:10,]
row.names(atoms_table_data) <- NULL
atoms_table_data %>% knitr::kable(col.names = c('res_name', 'Niezgodność liczy atomów')) %>% kable_styling()


```


Analogicznie postępujemy aby pokazać niezgodność liczby elektronów:

```{r niezgodnosc_elektrony}

electrons_incompatibility <- unique(select(data, res_name, local_res_atom_non_h_electron_sum, dict_atom_non_h_electron_sum))

electrons_incompatibility_with_diff <- mutate(electrons_incompatibility, diff = abs(local_res_atom_non_h_electron_sum - dict_atom_non_h_electron_sum))

electrons_incompatibility_with_diff_sorted <- electrons_incompatibility_with_diff[order(-electrons_incompatibility_with_diff$diff),]

electrons_table_data <- select(electrons_incompatibility_with_diff_sorted, res_name, diff)[1:10,]
row.names(electrons_table_data) <- NULL
electrons_table_data %>% knitr::kable(col.names = c('res_name', 'Niezgodność liczy elektronów')) %>% kable_styling()


```


#12. Rozkład wartości wszystkich kolumn zaczynających się od part_01

Na początek wyszukujemy nazwy kolumn zaczynające się od part_01.
Wyświetlamy 10 pierwszych.

``` {r rozklad_kolumny}

is_part_01_column <- colnames(data) %like% 'part_01'
part_01_column_names <- colnames(data)[is_part_01_column]
head(part_01_column_names, 10)

```

Następnie filtrujemy dane, przekształcamy do postaci: <nazwa kolumny, wartość>

```{r rozklad_wykres, cache=TRUE}

filtered_data <- data[is_part_01_column]

gathered_data <- gather(filtered_data, 'col_name', "value", part_01_column_names)
dim(gathered_data)

```

wyświetlamy rozkład wartości, osobny wykres dla każdej kolumny:

```{r rozklad_wykres2, fig.height = 90, cache=TRUE}

k <- ggplot(gathered_data, aes(x = gathered_data$value))
i <- k + facet_wrap(vars(gathered_data$col_name), ncol = 3, scales = "free")
i + geom_histogram(bins = 25) + xlab("Rozkład wartości")

```

#13. Interaktywny wykres z liczbą atomów, elektronów, oraz nazwą klasy
```{r interaktywny_wykres}
p <- ggplot(data, aes(local_res_atom_non_h_count, local_res_atom_non_h_electron_sum,
                       color=res_name)) + 
    geom_point() +
    xlab("Liczba atomów") +
    ylab("Liczba elektonów")
ggplotly(p)

```

#14. Przewidywanie liczby elektronów i atomów na podstawie innych kolumn

Filtrujemy dane do kolumn numerycznych.
Wykorzystujemy funkcję lm.

```{r regresja, cache = TRUE}

is_numeric_column_list <- unlist(lapply(data, is.numeric))
numeric_data <- data[, is_numeric_column_list]

without_electron <- names(numeric_data)[-which(names(numeric_data) =='local_res_atom_non_h_electron_sum')]

joined_query1 <- paste("local_res_atom_non_h_electron_sum ~ ", without_electron, sep = "")

electon_lm <- lm(joined_query1, numeric_data) #lm: fit linear models
electon_lm_summary <- summary(electon_lm)  

```

Szacowana trafność regresji:

R^2 

``` {r r21}
electon_lm_summary$r.squared
```

RMSE 

``` {r RMSE1}
sqrt(mean(electon_lm_summary$residuals^2))
```

Analogicznie postępujemy dla liczby elektronów:

```{r regresja2, cache = TRUE}

without_atoms <- names(numeric_data)[-which(names(numeric_data) =='local_res_atom_non_h_count')]

joined_query1 <- paste("local_res_atom_non_h_count ~ ",without_atoms,sep = "")

atom_lm <- lm(joined_query1, numeric_data) #lm: fit linear models
atom_lm_summary <- summary(atom_lm)  

```

Szacowana trafność regresji:

R^2 

``` {r r22}
atom_lm_summary$r.squared
```

RMSE 

``` {r RMSE2}
sqrt(mean(atom_lm_summary$residuals^2))
```



#15. Klasyfikator przewidujący wartość atrybutu res_name

Na początek oczyszczamy dane z kolumn, których nie powinniśmy brać do klasyfikacji:

```{r klasyfikator1}

columns_to_remove <- c('title','pdb_code','res_id',' chain_id','grid_space',' solvent_radius',' solvent_opening_radius',' part_step_FoFc_std_min',' part_step_FoFc_std_max',' part_step_FoFc_std_step')

cleaned_data <- data[ , -which(names(data) %in% columns_to_remove)]
cleaned_data <- cleaned_data %>% select(-starts_with("dict_"), -starts_with("local_"))

cleaned_data <- cleaned_data[, sapply(cleaned_data, nlevels) != 1]
```

Stratyfikujemy zbiór, trenujemy za pomocą algorytmu random forest:

```{r klasyfikator2, cache=TRUE}

inTraining <- 
    createDataPartition(
        # atrybut do stratyfikacji
        y = cleaned_data$res_name,
        p = .75,
        list = FALSE)


training <- cleaned_data[ inTraining,]
testing  <- cleaned_data[-inTraining,]


ctrl <- trainControl(
    # powtórzona ocena krzyżowa
    method = "repeatedcv",
    number = 2,
    repeats = 2)


# fit <- train(res_name ~ .,
#              data = training,
#              method = "rf",
#              trControl = ctrl)


```

Na koniec podsumowanie wyników:

```{r klasyfikator3}


# rfClasses <- predict(fit, newdata = testing)
# confusionMatrix(data = rfClasses, testing$Class)

```


